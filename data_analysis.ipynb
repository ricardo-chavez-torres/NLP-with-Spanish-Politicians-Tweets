{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import gensim\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import nlp_pipeline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-3-ad5961dd94ed>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-3-ad5961dd94ed>\"\u001B[1;36m, line \u001B[1;32m7\u001B[0m\n\u001B[1;33m    data_non_ner.insert(id = 6, \"Likes\", \"\")\u001B[0m\n\u001B[1;37m                               ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "data_non_ner = nlp_pipeline_result(\n",
    "    disable_ner=False,\n",
    "    parameters={\n",
    "        \"remove_hashtags\": True,\n",
    "        \"replace_politics\": True,\n",
    "        \"replace_parties\": True,\n",
    "    }\n",
    ")\n",
    "data_non_ner['n_lemmas'] = data_non_ner['Lemmas'].str.split().str.len()\n",
    "\n",
    "#data_non_ner.to_csv('data/data.csv',index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,50,10):\n",
    " display(data[i:i+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data['n_lemmas'].value_counts().sort_index().plot(kind=\"bar\",width=1,label='number of lemmas')\n",
    "plt.axvline(x = data['n_lemmas'].mean(),label='mean',color = 'black',linestyle = '--')\n",
    "plt.axvline(x = data['n_lemmas'].mode()[0],label='mode',color = 'red',linestyle = '--')\n",
    "plt.axvline(x = data['n_lemmas'].median(),label='median',color = 'green',linestyle = '--')\n",
    "plt.legend()\n",
    "plt.title('number of lemmas in tweet distribution')\n",
    "plt.xlabel('number of lemmas')\n",
    "plt.ylabel('number of tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['n_lemmas']>=3]\n",
    "print('Number of tweets in DataFrame after removing short tweets:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_corpus = data[\"Lemmas\"].tolist()\n",
    "tweets_corpus = list(set(tweets_corpus))\n",
    "tweets_corpus = [el.split() for el in tweets_corpus]\n",
    "\n",
    "# display(tweets_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.corpora.dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dic = gensim.corpora.Dictionary(tweets_corpus)\n",
    "\n",
    "# Filter token dictionary\n",
    "\n",
    "no_below = 5  # Minimum number of documents to keep a term in the dictionary\n",
    "no_above = .4  # Maximum proportion of documents in which a term can appear to be kept in the dictionary\n",
    "\n",
    "\n",
    "# BOW: Transform list of tokens into list of tuples (token id, token # of occurrences)\n",
    "\n",
    "tweets_corpus_bow = [token_dic.doc2bow(doc) for doc in tweets_corpus]\n",
    "\n",
    "tweets_corpus_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import LdaMallet\n",
    "import os\n",
    "\n",
    "os.environ['MALLET_HOME'] = r'C:/mallet'\n",
    "mallet_path = 'C:/mallet/bin/mallet'\n",
    "\n",
    "ldamallet = LdaMallet(mallet_path, corpus=tweets_corpus_bow, num_topics=20, id2word=token_dic, alpha=5, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 25\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(16, 20), sharex=True)\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Build a dataframe with columns 'token' and 'weight' for topic i\n",
    "    df = pd.DataFrame(ldamallet.show_topic(i, topn=topn), columns=['token','weight'])\n",
    "    sns.barplot(x='weight', y='token', data=df, color='c', orient='h', ax=axes[0][i])\n",
    "    axes[0][i].set_title('Topic ' + str(i))\n",
    "    # Build a dataframe with columns 'token' and 'weight' for topic i + 5\n",
    "    df = pd.DataFrame(ldamallet.show_topic(i+5, topn=topn), columns=['token','weight'])\n",
    "    sns.barplot(x='weight', y='token', data=df, color='c', orient='h', ax=axes[1][i])\n",
    "    axes[1][i].set_title('Topic ' + str(i+5))\n",
    "    # Build a dataframe with columns 'token' and 'weight' for topic i + 10\n",
    "    df = pd.DataFrame(ldamallet.show_topic(i+10, topn=topn), columns=['token','weight'])\n",
    "    sns.barplot(x='weight', y='token', data=df, color='c', orient='h', ax=axes[2][i])\n",
    "    axes[2][i].set_title('Topic ' + str(i+10))\n",
    "    # Build a dataframe with columns 'token' and 'weight' for topic i + 15\n",
    "    df = pd.DataFrame(ldamallet.show_topic(i + 15, topn=topn), columns=['token','weight'])\n",
    "    sns.barplot(x='weight', y='token', data=df, color='c', orient='h', ax=axes[3][i])\n",
    "    axes[3][i].set_title('Topic ' + str(i + 15))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    top_topics = ldamallet.get_document_topics(train_corpus[i], minimum_probability=0.0)\n",
    "    lda_topics_vector = [top_topics[i][1] for i in range(number_of_topics)]\n",
    "    lda_topics_vector.extend([my_dataframe.iloc[i].favs])  # count of favs\n",
    "    lda_topics_vector.extend([len(my_dataframe.iloc[i].retweets)])  # count of retweets\n",
    "    train_vecs.append(topic_vec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}